# logstash-7.2.0/bin/logstash -f logstash.conf 
#
input {
  file {
    path => "/home/pgoldtho/logstash/tinysdf.csv"
    start_position => "beginning"
   sincedb_path => "/dev/null"
  }
}
filter {
  csv {
      separator => ","
      skip_header => true
      columns => ["CO_NO","PARCEL_ID","ASMNT_YR","ATV_STRT","GRP_NO","DOR_UC","NBRHD_CD","MKT_AR","CENSUS_BK","SALE_ID_CD","SAL_CHG_CD",
                 "VI_CD","OR_BOOK","OR_PAGE","CLERK_NO","QUAL_CD","SALE_YR","SALE_MO","SALE_PRC","MULTI_PAR_SAL","RS_ID","MP_ID","STATE_PARCEL_ID",
                 "COUNTY_NAME","USAGE","SALE_TYPE","SALE_DESC","GEO_COORDS"]
  }
  mutate {convert => ["CO_NO", "integer"]}
  mutate {convert => ["ASMNT_YR", "integer"]}
  mutate {convert => ["ATV_STRT", "integer"]}
  mutate {convert => ["GRP_NO", "integer"]}
  mutate {convert => ["DOR_UC", "integer"]}
  mutate {convert => ["SAL_CHG_CD", "integer"]}
  mutate {convert => ["QUAL_CD", "integer"]}
  mutate {convert => ["SALE_YR", "integer"]}
  mutate {convert => ["SALE_MO", "integer"]}
  mutate {convert => ["SALE_PRC", "integer"]}
  mutate {
          remove_field => ["path", "host", "message", "@timestamp", "@version"]
         }

  mutate { gsub => ["GEO_COORDS", "'", '"']}
  json { source => "GEO_COORDS" }

}
output {
   elasticsearch {
     hosts => "http://localhost:9200"
     index => "sdf3"
  }
stdout {}
}
