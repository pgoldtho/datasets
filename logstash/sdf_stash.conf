# logstash-7.2.0/bin/logstash -f logstash.conf
#
input {
  file {
    path => "/home/pgoldtho/git/dor-parse/resources/data/2018out/sdf/SDF15*.csv"
    start_position => "beginning"
   sincedb_path => "/dev/null"
  }
}
filter {
  csv {
      separator => ","
      skip_header => true
      quote_char => "'"
      columns => ["CO_NO","PARCEL_ID","ASMNT_YR","ATV_STRT","GRP_NO","DOR_UC","NBRHD_CD","MKT_AR","CENSUS_BK","SALE_ID_CD","SAL_CHG_CD",
                 "VI_CD","OR_BOOK","OR_PAGE","CLERK_NO","QUAL_CD","SALE_YR","SALE_MO","SALE_PRC","MULTI_PAR_SAL","RS_ID","MP_ID","STATE_PARCEL_ID",
                 "COUNTY_NAME","USAGE","SALE_TYPE","SALE_DESC","GEO_COORDS","GEO_CENTROID"]
  }
  mutate {convert => ["CO_NO", "integer"]}
  mutate {convert => ["ASMNT_YR", "integer"]}
  mutate {convert => ["ATV_STRT", "integer"]}
  mutate {convert => ["GRP_NO", "integer"]}
  mutate {convert => ["DOR_UC", "integer"]}
  mutate {convert => ["SAL_CHG_CD", "integer"]}
  mutate {convert => ["QUAL_CD", "integer"]}
  mutate {convert => ["SALE_YR", "integer"]}
  mutate {convert => ["SALE_MO", "integer"]}
  mutate {convert => ["SALE_PRC", "integer"]}
  json { source => "GEO_CENTROID"
         target => "parsed_geojson" }

  mutate {
         remove_field => ["GEO_CENTROID"]
         }

  mutate {
    add_field => { "GEO_CENTROID" => "%{[parsed_geojson][coordinates][1]}, %{[parsed_geojson][coordinates][0]}" }
         }

  mutate {
          remove_field => ["path", "host", "message", "@timestamp", "@version", "parsed_geojson"]
         }

  json { source => "GEO_COORDS"
         target => "GEO_COORDS" }


}
output {
   elasticsearch {
     hosts => "http://10.0.0.30:9200"
     index => "sdf2018d"
  }
stdout {}
}
